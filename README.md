# Super-Resolution Generative Adversarial Network (SR-GAN)

This repository contains an implementation of a **Super-Resolution Generative Adversarial Network (SR-GAN)** using **PyTorch**. SR-GAN enhances image resolution by generating high-quality images from low-resolution inputs. The model is trained on the **ImageNet dataset** to demonstrate its functionality and performance.


## Introduction

The objective of this project is to build an SR-GAN capable of improving image resolution through a generator-discriminator framework, following the original design proposed in the SR-GAN paper.

## Model Architecture

The SR-GAN architecture comprises:

- **Generator**: Upscales low-resolution images to high-resolution ones. It consists of several convolutional layers, upsampling layers, and residual blocks, incorporating **PReLU** and **LeakyReLU** activation functions to introduce non-linearity.

- **Discriminator**: Distinguishes between real high-resolution images and those generated by the Generator. Built on a convolutional layer followed by a fully connected layer, it uses LeakyReLU activation in its convolutional blocks.

## Loss Functions

- **VGG Loss**: Computes the mean squared error between features extracted by a pre-trained VGG19 network from the generated and target high-resolution images, ensuring that the generated features are comparable to those of the target images.

- **Binary Cross-Entropy (BCE) Loss**: Used for training the Discriminator by measuring the discrepancy between actual and predicted distributions of real and generated images.

## Training Process

The model was trained for **1000 epochs** on the ImageNet dataset. The **Adam optimizer** was utilized with a learning rate of **0.0002** and momentum parameters (betas) of **(0.5, 0.999)** for both the Generator and the Discriminator. The training loop alternated between optimizing the Generator and the Discriminator.

## Results

After training for 1000 epochs, we observed a decrease in losses for both the Discriminator and Generator, indicating improved performance. Sample output images are provided below.

## Figures

- **Figure 1**: [Description]
- **Figure 2**: [Description]
- **Figure 3**: Output after 50 epochs.
- **Figure 4**: Output after 500 epochs.
- **Figure 5**: Output after 1000 epochs.
- **Figure 6**: Sample output on test images.

## References

- [SRGAN Paper](https://arxiv.org/abs/1703.10524) (Link to the original paper for further reading)
